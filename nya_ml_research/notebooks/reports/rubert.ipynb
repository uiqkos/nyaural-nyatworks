{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.utils import gen_batches, shuffle\n",
    "from scikitplot.metrics import plot_roc, plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nya_ml.models.skolkovoInstitute_russian_toxicity_classifier import RuToxicityClassifier\n",
    "from nya_ml_research.config import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = RuToxicityClassifier.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.981254 to fit\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "'rnn_torchviz.png'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "inputs = model.tokenizer('всем привет', max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "outputs = model.model(**inputs)\n",
    "\n",
    "make_dot(\n",
    "    outputs.logits,\n",
    "    params=dict(list(model.model.named_parameters()))\n",
    ").render(\"rnn_torchviz\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH / 'raw' / 'toxic' / 'kaggle-ru-toxic-comments.csv', names=['text', 'label'], skiprows=1)\n",
    "# df = pd.read_csv(DATA_PATH / 'raw' / 'toxic' / 'kaggle-ru-toxic-social-network.csv', names=['text', 'label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n2                          Собаке - собачья смерть\\n    1.0\n3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n5  Для каких стан является эталоном современная с...    1.0\n6  В шапке были ссылки на инфу по текущему фильму...    0.0\n7  УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...    1.0\n8                      Ебать тебя разносит, шизик.\\n    1.0\n9                          Обосрался, сиди обтекай\\n    1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Собаке - собачья смерть\\n</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Для каких стан является эталоном современная с...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ебать тебя разносит, шизик.\\n</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Обосрался, сиди обтекай\\n</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "shuffle_df = shuffle(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/225 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "370530eb310046bd8d222839dee3da05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [58]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(gen_batches(\u001B[38;5;28mlen\u001B[39m(shuffle_df\u001B[38;5;241m.\u001B[39mtext), \u001B[38;5;241m64\u001B[39m), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(shuffle_df\u001B[38;5;241m.\u001B[39mtext) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m64\u001B[39m)):\n\u001B[1;32m----> 4\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshuffle_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[:, \u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      5\u001B[0m     y_pred\u001B[38;5;241m.\u001B[39mappend(pred)\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\projects\\nyaural_nyatworks\\nya_ml\\models\\bertclassifier.py:26\u001B[0m, in \u001B[0;36mBertClassifier._predict\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[0;32m     25\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer(text, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 26\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m     27\u001B[0m     predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(outputs\u001B[38;5;241m.\u001B[39mlogits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predicted\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1545\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1539\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1540\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1541\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1542\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1543\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1545\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1546\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1549\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1551\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1552\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1553\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1555\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1557\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1559\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    987\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m    989\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    990\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    991\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    994\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    995\u001B[0m )\n\u001B[1;32m--> 996\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1005\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1008\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1009\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    576\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    577\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    578\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    582\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    583\u001B[0m     )\n\u001B[0;32m    584\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 585\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    595\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    462\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    469\u001B[0m ):\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    471\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 472\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    479\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    481\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    394\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    400\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    401\u001B[0m ):\n\u001B[1;32m--> 402\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    411\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    412\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:268\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    266\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    267\u001B[0m ):\n\u001B[1;32m--> 268\u001B[0m     mixed_query_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001B[39;00m\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001B[39;00m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001B[39;00m\n\u001B[0;32m    273\u001B[0m     is_cross_attention \u001B[38;5;241m=\u001B[39m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# y_pred = list(tqdm(map(predict, df.comment)))\n",
    "y_pred = []\n",
    "for batch in tqdm(gen_batches(len(shuffle_df.text), 64), total=int(len(shuffle_df.text) / 64)):\n",
    "    pred = model._predict(shuffle_df.text[batch].values.tolist())[:, 1].numpy()\n",
    "    y_pred.append(pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "y_pred_flatten = np.concatenate(y_pred)\n",
    "y_true = shuffle_df.label[:len(y_pred_flatten)]\n",
    "y_pred_2_classes = np.vstack([1 - y_pred_flatten, y_pred_flatten]).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "8064"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_flatten)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc = plot_roc(\n",
    "    y_true, y_pred_2_classes,\n",
    "    title='Russian Language Toxic Comments from 2ch, Pikabu',\n",
    "    plot_macro=False, plot_micro=False, classes_to_plot=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "roc.get_figure().savefig('roc_curve_kaggle_2ch_pikabu_toxic_skolkovo.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.86393290e-04,\n        1.86393290e-04, 1.86393290e-04, 1.86393290e-04, 1.86393290e-04,\n        1.86393290e-04, 1.86393290e-04, 1.86393290e-04, 1.86393290e-04,\n        1.86393290e-04, 1.86393290e-04, 1.86393290e-04, 3.72786580e-04,\n        3.72786580e-04, 3.72786580e-04, 3.72786580e-04, 3.72786580e-04,\n        3.72786580e-04, 3.72786580e-04, 3.72786580e-04, 5.59179870e-04,\n        5.59179870e-04, 7.45573159e-04, 7.45573159e-04, 7.45573159e-04,\n        7.45573159e-04, 9.31966449e-04, 9.31966449e-04, 1.11835974e-03,\n        1.11835974e-03, 1.30475303e-03, 1.30475303e-03, 1.30475303e-03,\n        1.30475303e-03, 1.30475303e-03, 1.30475303e-03, 1.30475303e-03,\n        1.49114632e-03, 1.49114632e-03, 1.49114632e-03, 1.49114632e-03,\n        1.67753961e-03, 1.67753961e-03, 1.86393290e-03, 1.86393290e-03,\n        1.86393290e-03, 1.86393290e-03, 1.86393290e-03, 1.86393290e-03,\n        2.05032619e-03, 2.05032619e-03, 2.23671948e-03, 2.23671948e-03,\n        2.42311277e-03, 2.42311277e-03, 2.60950606e-03, 2.60950606e-03,\n        2.79589935e-03, 2.79589935e-03, 2.98229264e-03, 2.98229264e-03,\n        3.16868593e-03, 3.16868593e-03, 3.35507922e-03, 3.35507922e-03,\n        3.35507922e-03, 3.35507922e-03, 3.35507922e-03, 3.35507922e-03,\n        3.54147251e-03, 3.54147251e-03, 3.72786580e-03, 3.72786580e-03,\n        3.91425909e-03, 3.91425909e-03, 4.10065238e-03, 4.10065238e-03,\n        4.10065238e-03, 4.10065238e-03, 4.10065238e-03, 4.10065238e-03,\n        4.10065238e-03, 4.10065238e-03, 4.28704567e-03, 4.28704567e-03,\n        4.47343896e-03, 4.47343896e-03, 4.65983225e-03, 4.65983225e-03,\n        4.84622554e-03, 4.84622554e-03, 4.84622554e-03, 4.84622554e-03,\n        4.84622554e-03, 4.84622554e-03, 4.84622554e-03, 4.84622554e-03,\n        5.03261883e-03, 5.03261883e-03, 5.21901212e-03, 5.21901212e-03,\n        5.40540541e-03, 5.40540541e-03, 5.59179870e-03, 5.59179870e-03,\n        5.77819199e-03, 5.77819199e-03, 5.96458527e-03, 5.96458527e-03,\n        6.15097856e-03, 6.15097856e-03, 6.33737185e-03, 6.33737185e-03,\n        6.52376514e-03, 6.52376514e-03, 6.71015843e-03, 6.71015843e-03,\n        6.89655172e-03, 6.89655172e-03, 7.08294501e-03, 7.08294501e-03,\n        7.26933830e-03, 7.26933830e-03, 7.45573159e-03, 7.45573159e-03,\n        7.64212488e-03, 7.64212488e-03, 7.64212488e-03, 8.01491146e-03,\n        8.01491146e-03, 8.20130475e-03, 8.20130475e-03, 8.38769804e-03,\n        8.38769804e-03, 8.57409133e-03, 8.57409133e-03, 8.76048462e-03,\n        8.76048462e-03, 9.13327120e-03, 9.13327120e-03, 9.13327120e-03,\n        9.31966449e-03, 9.31966449e-03, 9.50605778e-03, 9.50605778e-03,\n        9.69245107e-03, 9.69245107e-03, 9.87884436e-03, 9.87884436e-03,\n        1.00652377e-02, 1.00652377e-02, 1.02516309e-02, 1.02516309e-02,\n        1.04380242e-02, 1.04380242e-02, 1.06244175e-02, 1.06244175e-02,\n        1.08108108e-02, 1.08108108e-02, 1.09972041e-02, 1.09972041e-02,\n        1.11835974e-02, 1.11835974e-02, 1.13699907e-02, 1.13699907e-02,\n        1.17427773e-02, 1.17427773e-02, 1.19291705e-02, 1.19291705e-02,\n        1.21155638e-02, 1.21155638e-02, 1.24883504e-02, 1.24883504e-02,\n        1.26747437e-02, 1.26747437e-02, 1.28611370e-02, 1.28611370e-02,\n        1.30475303e-02, 1.30475303e-02, 1.32339236e-02, 1.32339236e-02,\n        1.34203169e-02, 1.34203169e-02, 1.36067102e-02, 1.36067102e-02,\n        1.37931034e-02, 1.37931034e-02, 1.39794967e-02, 1.39794967e-02,\n        1.41658900e-02, 1.41658900e-02, 1.43522833e-02, 1.43522833e-02,\n        1.45386766e-02, 1.45386766e-02, 1.47250699e-02, 1.47250699e-02,\n        1.49114632e-02, 1.49114632e-02, 1.50978565e-02, 1.50978565e-02,\n        1.52842498e-02, 1.52842498e-02, 1.56570363e-02, 1.56570363e-02,\n        1.58434296e-02, 1.58434296e-02, 1.60298229e-02, 1.60298229e-02,\n        1.62162162e-02, 1.62162162e-02, 1.65890028e-02, 1.65890028e-02,\n        1.67753961e-02, 1.67753961e-02, 1.69617894e-02, 1.69617894e-02,\n        1.71481827e-02, 1.71481827e-02, 1.73345760e-02, 1.73345760e-02,\n        1.75209692e-02, 1.75209692e-02, 1.78937558e-02, 1.78937558e-02,\n        1.80801491e-02, 1.80801491e-02, 1.82665424e-02, 1.82665424e-02,\n        1.84529357e-02, 1.84529357e-02, 1.86393290e-02, 1.86393290e-02,\n        1.90121156e-02, 1.90121156e-02, 1.93849021e-02, 1.93849021e-02,\n        1.95712954e-02, 1.95712954e-02, 1.97576887e-02, 1.97576887e-02,\n        1.99440820e-02, 1.99440820e-02, 2.01304753e-02, 2.01304753e-02,\n        2.05032619e-02, 2.05032619e-02, 2.06896552e-02, 2.06896552e-02,\n        2.08760485e-02, 2.08760485e-02, 2.12488350e-02, 2.12488350e-02,\n        2.14352283e-02, 2.14352283e-02, 2.16216216e-02, 2.16216216e-02,\n        2.18080149e-02, 2.18080149e-02, 2.19944082e-02, 2.19944082e-02,\n        2.21808015e-02, 2.21808015e-02, 2.23671948e-02, 2.23671948e-02,\n        2.27399814e-02, 2.27399814e-02, 2.29263747e-02, 2.29263747e-02,\n        2.32991612e-02, 2.32991612e-02, 2.34855545e-02, 2.34855545e-02,\n        2.36719478e-02, 2.36719478e-02, 2.38583411e-02, 2.38583411e-02,\n        2.40447344e-02, 2.40447344e-02, 2.42311277e-02, 2.42311277e-02,\n        2.44175210e-02, 2.44175210e-02, 2.46039143e-02, 2.46039143e-02,\n        2.47903075e-02, 2.47903075e-02, 2.49767008e-02, 2.49767008e-02,\n        2.51630941e-02, 2.51630941e-02, 2.55358807e-02, 2.55358807e-02,\n        2.59086673e-02, 2.59086673e-02, 2.60950606e-02, 2.60950606e-02,\n        2.62814539e-02, 2.62814539e-02, 2.64678472e-02, 2.64678472e-02,\n        2.66542404e-02, 2.66542404e-02, 2.68406337e-02, 2.68406337e-02,\n        2.70270270e-02, 2.70270270e-02, 2.72134203e-02, 2.72134203e-02,\n        2.73998136e-02, 2.73998136e-02, 2.75862069e-02, 2.75862069e-02,\n        2.77726002e-02, 2.77726002e-02, 2.79589935e-02, 2.79589935e-02,\n        2.81453868e-02, 2.81453868e-02, 2.83317801e-02, 2.83317801e-02,\n        2.85181733e-02, 2.85181733e-02, 2.90773532e-02, 2.90773532e-02,\n        2.92637465e-02, 2.92637465e-02, 2.94501398e-02, 2.94501398e-02,\n        2.96365331e-02, 2.96365331e-02, 2.98229264e-02, 2.98229264e-02,\n        3.00093197e-02, 3.00093197e-02, 3.01957130e-02, 3.01957130e-02,\n        3.07548928e-02, 3.07548928e-02, 3.09412861e-02, 3.09412861e-02,\n        3.11276794e-02, 3.11276794e-02, 3.16868593e-02, 3.16868593e-02,\n        3.18732526e-02, 3.18732526e-02, 3.22460391e-02, 3.22460391e-02,\n        3.31780056e-02, 3.31780056e-02, 3.33643989e-02, 3.33643989e-02,\n        3.35507922e-02, 3.35507922e-02, 3.37371855e-02, 3.37371855e-02,\n        3.42963653e-02, 3.42963653e-02, 3.44827586e-02, 3.44827586e-02,\n        3.46691519e-02, 3.46691519e-02, 3.48555452e-02, 3.48555452e-02,\n        3.50419385e-02, 3.50419385e-02, 3.56011184e-02, 3.56011184e-02,\n        3.59739049e-02, 3.59739049e-02, 3.65330848e-02, 3.65330848e-02,\n        3.67194781e-02, 3.70922647e-02, 3.70922647e-02, 3.72786580e-02,\n        3.72786580e-02, 3.76514445e-02, 3.76514445e-02, 3.78378378e-02,\n        3.78378378e-02, 3.80242311e-02, 3.80242311e-02, 3.82106244e-02,\n        3.82106244e-02, 3.83970177e-02, 3.83970177e-02, 3.91425909e-02,\n        3.91425909e-02, 3.97017707e-02, 3.97017707e-02, 3.98881640e-02,\n        3.98881640e-02, 4.04473439e-02, 4.04473439e-02, 4.06337372e-02,\n        4.06337372e-02, 4.10065238e-02, 4.10065238e-02, 4.11929171e-02,\n        4.11929171e-02, 4.13793103e-02, 4.13793103e-02, 4.15657036e-02,\n        4.15657036e-02, 4.21248835e-02, 4.21248835e-02, 4.23112768e-02,\n        4.23112768e-02, 4.24976701e-02, 4.24976701e-02, 4.26840634e-02,\n        4.26840634e-02, 4.28704567e-02, 4.28704567e-02, 4.30568500e-02,\n        4.30568500e-02, 4.32432432e-02, 4.32432432e-02, 4.34296365e-02,\n        4.34296365e-02, 4.39888164e-02, 4.39888164e-02, 4.49207829e-02,\n        4.49207829e-02, 4.51071761e-02, 4.51071761e-02, 4.52935694e-02,\n        4.52935694e-02, 4.58527493e-02, 4.58527493e-02, 4.65983225e-02,\n        4.65983225e-02, 4.67847158e-02, 4.67847158e-02, 4.69711090e-02,\n        4.69711090e-02, 4.73438956e-02, 4.73438956e-02, 4.75302889e-02,\n        4.75302889e-02, 4.88350419e-02, 4.88350419e-02, 4.92078285e-02,\n        4.92078285e-02, 4.97670084e-02, 4.97670084e-02, 4.99534017e-02,\n        4.99534017e-02, 5.05125815e-02, 5.05125815e-02, 5.06989748e-02,\n        5.06989748e-02, 5.10717614e-02, 5.10717614e-02, 5.12581547e-02,\n        5.12581547e-02, 5.16309413e-02, 5.16309413e-02, 5.20037279e-02,\n        5.20037279e-02, 5.21901212e-02, 5.21901212e-02, 5.23765144e-02,\n        5.23765144e-02, 5.27493010e-02, 5.29356943e-02, 5.31220876e-02,\n        5.31220876e-02, 5.38676608e-02, 5.38676608e-02, 5.46132339e-02,\n        5.46132339e-02, 5.49860205e-02, 5.49860205e-02, 5.51724138e-02,\n        5.51724138e-02, 5.55452004e-02, 5.55452004e-02, 5.62907735e-02,\n        5.62907735e-02, 5.64771668e-02, 5.64771668e-02, 5.66635601e-02,\n        5.66635601e-02, 5.75955266e-02, 5.75955266e-02, 5.77819199e-02,\n        5.77819199e-02, 5.85274930e-02, 5.85274930e-02, 5.98322460e-02,\n        5.98322460e-02, 6.03914259e-02, 6.03914259e-02, 6.05778192e-02,\n        6.05778192e-02, 6.07642125e-02, 6.07642125e-02, 6.11369991e-02,\n        6.11369991e-02, 6.13233924e-02, 6.13233924e-02, 6.15097856e-02,\n        6.15097856e-02, 6.18825722e-02, 6.18825722e-02, 6.20689655e-02,\n        6.20689655e-02, 6.26281454e-02, 6.26281454e-02, 6.44920783e-02,\n        6.44920783e-02, 6.46784716e-02, 6.46784716e-02, 6.52376514e-02,\n        6.52376514e-02, 6.54240447e-02, 6.54240447e-02, 6.61696179e-02,\n        6.63560112e-02, 6.74743709e-02, 6.74743709e-02, 6.80335508e-02,\n        6.80335508e-02, 6.82199441e-02, 6.82199441e-02, 6.84063374e-02,\n        6.84063374e-02, 6.89655172e-02, 6.89655172e-02, 6.93383038e-02,\n        6.93383038e-02, 7.04566636e-02, 7.04566636e-02, 7.12022367e-02,\n        7.15750233e-02, 7.17614166e-02, 7.21342032e-02, 7.21342032e-02,\n        7.28797763e-02, 7.28797763e-02, 7.32525629e-02, 7.32525629e-02,\n        7.36253495e-02, 7.36253495e-02, 7.38117428e-02, 7.38117428e-02,\n        7.39981361e-02, 7.39981361e-02, 7.45573159e-02, 7.45573159e-02,\n        7.47437092e-02, 7.47437092e-02, 7.53028891e-02, 7.53028891e-02,\n        7.54892824e-02, 7.54892824e-02, 7.66076421e-02, 7.66076421e-02,\n        7.69804287e-02, 7.69804287e-02, 7.79123952e-02, 7.79123952e-02,\n        7.88443616e-02, 7.88443616e-02, 7.92171482e-02, 7.92171482e-02,\n        7.94035415e-02, 7.94035415e-02, 8.03355079e-02, 8.03355079e-02,\n        8.05219012e-02, 8.05219012e-02, 8.07082945e-02, 8.07082945e-02,\n        8.21994408e-02, 8.21994408e-02, 8.25722274e-02, 8.25722274e-02,\n        8.27586207e-02, 8.27586207e-02, 8.38769804e-02, 8.38769804e-02,\n        8.40633737e-02, 8.40633737e-02, 8.48089469e-02, 8.51817335e-02,\n        8.59273066e-02, 8.59273066e-02, 8.61136999e-02, 8.61136999e-02,\n        8.63000932e-02, 8.66728798e-02, 8.66728798e-02, 8.90959925e-02,\n        8.90959925e-02, 9.00279590e-02, 9.00279590e-02, 9.02143523e-02,\n        9.02143523e-02, 9.31966449e-02, 9.31966449e-02, 9.41286114e-02,\n        9.41286114e-02, 9.43150047e-02, 9.43150047e-02, 9.52469711e-02,\n        9.52469711e-02, 9.71109040e-02, 9.71109040e-02, 9.74836906e-02,\n        9.74836906e-02, 9.82292637e-02, 9.82292637e-02, 9.84156570e-02,\n        9.84156570e-02, 9.86020503e-02, 9.87884436e-02, 9.87884436e-02,\n        9.95340168e-02, 9.95340168e-02, 1.01770736e-01, 1.01770736e-01,\n        1.02143523e-01, 1.02143523e-01, 1.03448276e-01, 1.03448276e-01,\n        1.04566636e-01, 1.04566636e-01, 1.04753029e-01, 1.04753029e-01,\n        1.05125815e-01, 1.05125815e-01, 1.05312209e-01, 1.05312209e-01,\n        1.05498602e-01, 1.05498602e-01, 1.06057782e-01, 1.06057782e-01,\n        1.07548928e-01, 1.07548928e-01, 1.07735322e-01, 1.08108108e-01,\n        1.09599254e-01, 1.09599254e-01, 1.10904007e-01, 1.10904007e-01,\n        1.12208760e-01, 1.12208760e-01, 1.13886300e-01, 1.13886300e-01,\n        1.16682199e-01, 1.16682199e-01, 1.17614166e-01, 1.17614166e-01,\n        1.18546132e-01, 1.18546132e-01, 1.18732526e-01, 1.19105312e-01,\n        1.19850885e-01, 1.19850885e-01, 1.23019571e-01, 1.23019571e-01,\n        1.23765144e-01, 1.23765144e-01, 1.26001864e-01, 1.26374651e-01,\n        1.26561044e-01, 1.26561044e-01, 1.28052190e-01, 1.28052190e-01,\n        1.29916123e-01, 1.29916123e-01, 1.30102516e-01, 1.30102516e-01,\n        1.31407269e-01, 1.31407269e-01, 1.31966449e-01, 1.31966449e-01,\n        1.32525629e-01, 1.32525629e-01, 1.33271202e-01, 1.33271202e-01,\n        1.34575955e-01, 1.34575955e-01, 1.36626281e-01, 1.36626281e-01,\n        1.41099720e-01, 1.41099720e-01, 1.43336440e-01, 1.43336440e-01,\n        1.43709226e-01, 1.45386766e-01, 1.45386766e-01, 1.50978565e-01,\n        1.50978565e-01, 1.51910531e-01, 1.51910531e-01, 1.56756757e-01,\n        1.56756757e-01, 1.61043802e-01, 1.61043802e-01, 1.62907735e-01,\n        1.62907735e-01, 1.65330848e-01, 1.65517241e-01, 1.67567568e-01,\n        1.67567568e-01, 1.73159366e-01, 1.73159366e-01, 1.74464119e-01,\n        1.74464119e-01, 1.74650513e-01, 1.74650513e-01, 1.80428705e-01,\n        1.80428705e-01, 1.82106244e-01, 1.82106244e-01, 1.89002796e-01,\n        1.89375582e-01, 1.90493942e-01, 1.90493942e-01, 1.96085741e-01,\n        1.96085741e-01, 2.04473439e-01, 2.04659832e-01, 2.05032619e-01,\n        2.05032619e-01, 2.06523765e-01, 2.06523765e-01, 2.12488350e-01,\n        2.12488350e-01, 2.14911463e-01, 2.14911463e-01, 2.17334576e-01,\n        2.17707363e-01, 2.21062442e-01, 2.21062442e-01, 2.21435228e-01,\n        2.21435228e-01, 2.22367195e-01, 2.22367195e-01, 2.26095061e-01,\n        2.26095061e-01, 2.26467847e-01, 2.26467847e-01, 2.29822926e-01,\n        2.29822926e-01, 2.35414725e-01, 2.35787512e-01, 2.39515377e-01,\n        2.39515377e-01, 2.40074557e-01, 2.40447344e-01, 2.49394222e-01,\n        2.49394222e-01, 2.50512582e-01, 2.50512582e-01, 2.51630941e-01,\n        2.52003728e-01, 2.57968313e-01, 2.58341100e-01, 2.66169618e-01,\n        2.66169618e-01, 2.72320596e-01, 2.72320596e-01, 2.73998136e-01,\n        2.73998136e-01, 2.74370923e-01, 2.74370923e-01, 2.81453868e-01,\n        2.81453868e-01, 2.85368127e-01, 2.85740913e-01, 2.88536813e-01,\n        2.88536813e-01, 2.90214352e-01, 2.90214352e-01, 2.92264678e-01,\n        2.92264678e-01, 2.97856477e-01, 2.97856477e-01, 2.99534017e-01,\n        2.99534017e-01, 3.00465983e-01, 3.00465983e-01, 3.10904007e-01,\n        3.10904007e-01, 3.16868593e-01, 3.17241379e-01, 3.18173346e-01,\n        3.18173346e-01, 3.23392358e-01, 3.23392358e-01, 3.24883504e-01,\n        3.25256291e-01, 3.50605778e-01, 3.50605778e-01, 3.52469711e-01,\n        3.52469711e-01, 3.58993476e-01, 3.58993476e-01, 3.63839702e-01,\n        3.63839702e-01, 3.64771668e-01, 3.64771668e-01, 3.64958062e-01,\n        3.65517241e-01, 3.73532153e-01, 3.73532153e-01, 3.83783784e-01,\n        3.83783784e-01, 3.92917055e-01, 3.93289842e-01, 3.95153774e-01,\n        3.95526561e-01, 3.97763281e-01, 3.97763281e-01, 4.03727866e-01,\n        4.03727866e-01, 4.10624418e-01, 4.10997204e-01, 4.17520969e-01,\n        4.17707363e-01, 4.31500466e-01, 4.31686859e-01, 4.32618826e-01,\n        4.32618826e-01, 4.53494874e-01, 4.53494874e-01, 4.70829450e-01,\n        4.70829450e-01, 4.72693383e-01, 4.72693383e-01, 4.78098788e-01,\n        4.78098788e-01, 4.89655172e-01, 4.90027959e-01, 4.93755825e-01,\n        4.93755825e-01, 4.95246971e-01, 4.95619758e-01, 4.98042870e-01,\n        4.98042870e-01, 4.98415657e-01, 4.98788444e-01, 5.14259087e-01,\n        5.14259087e-01, 5.30661696e-01, 5.31034483e-01, 5.39794967e-01,\n        5.39794967e-01, 5.39981361e-01, 5.39981361e-01, 5.62348555e-01,\n        5.62348555e-01, 5.63839702e-01, 5.64212488e-01, 5.75955266e-01,\n        5.75955266e-01, 5.95153774e-01, 5.95153774e-01, 6.09692451e-01,\n        6.09692451e-01, 6.21994408e-01, 6.21994408e-01, 6.28145387e-01,\n        6.28145387e-01, 6.28518173e-01, 6.28518173e-01, 6.44734390e-01,\n        6.45107176e-01, 6.65424045e-01, 6.65796831e-01, 6.66356011e-01,\n        6.66728798e-01, 6.71388630e-01, 6.71761417e-01, 6.72506990e-01,\n        6.72506990e-01, 6.84808947e-01, 6.84808947e-01, 6.87418453e-01,\n        6.87418453e-01, 7.08294501e-01, 7.08667288e-01, 7.30102516e-01,\n        7.30288910e-01, 7.35321528e-01, 7.35321528e-01, 7.39794967e-01,\n        7.39794967e-01, 7.48741845e-01, 7.48741845e-01, 7.53774464e-01,\n        7.54147251e-01, 7.67194781e-01, 7.67194781e-01, 7.77073625e-01,\n        7.77073625e-01, 7.83038211e-01, 7.83038211e-01, 7.86766076e-01,\n        7.86766076e-01, 7.93103448e-01, 7.93476235e-01, 8.03355079e-01,\n        8.03727866e-01, 8.20689655e-01, 8.20689655e-01, 8.36160298e-01,\n        8.36533085e-01, 8.47157502e-01, 8.47157502e-01, 8.49580615e-01,\n        8.49580615e-01, 8.52935694e-01, 8.52935694e-01, 8.55731594e-01,\n        8.55731594e-01, 8.68779124e-01, 8.68779124e-01, 8.77166822e-01,\n        8.77539609e-01, 8.78844362e-01, 8.78844362e-01, 8.79589935e-01,\n        8.79962721e-01, 8.83131407e-01, 8.83504194e-01, 8.93942218e-01,\n        8.94315005e-01, 8.98229264e-01, 8.98602050e-01, 8.98602050e-01,\n        9.11090401e-01, 9.11463187e-01, 9.19105312e-01, 9.19105312e-01,\n        9.21714818e-01, 9.22087605e-01, 9.23205965e-01, 9.23578751e-01,\n        9.29916123e-01, 9.29916123e-01, 9.38303821e-01, 9.38676608e-01,\n        9.64398882e-01, 9.64771668e-01, 9.66262815e-01, 9.66262815e-01,\n        9.67381174e-01, 9.67381174e-01, 9.71109040e-01, 9.71109040e-01,\n        9.91612302e-01, 9.91985089e-01, 1.00000000e+00]),\n array([0.00000000e+00, 3.70507595e-04, 1.59318266e-02, 1.59318266e-02,\n        2.92701000e-02, 3.00111152e-02, 4.48314190e-02, 4.55724342e-02,\n        6.22452760e-02, 6.29862912e-02, 9.00333457e-02, 9.07743609e-02,\n        1.00037051e-01, 1.00778066e-01, 1.37458318e-01, 1.37458318e-01,\n        1.44868470e-01, 1.45609485e-01, 1.55983698e-01, 1.56724713e-01,\n        1.61170804e-01, 1.61911819e-01, 1.73027047e-01, 1.73027047e-01,\n        1.76732123e-01, 1.76732123e-01, 1.77473138e-01, 1.78214153e-01,\n        1.84512783e-01, 1.84512783e-01, 1.87476843e-01, 1.87476843e-01,\n        1.94145980e-01, 1.94145980e-01, 1.94886995e-01, 2.15264913e-01,\n        2.16005928e-01, 2.17858466e-01, 2.18599481e-01, 2.46758059e-01,\n        2.46758059e-01, 2.65283438e-01, 2.66024454e-01, 2.83438310e-01,\n        2.83438310e-01, 2.83808818e-01, 2.83808818e-01, 2.92701000e-01,\n        2.93442016e-01, 2.94924046e-01, 2.95665061e-01, 2.96035569e-01,\n        2.96035569e-01, 3.00111152e-01, 3.00111152e-01, 3.03816228e-01,\n        3.03816228e-01, 3.07521304e-01, 3.07521304e-01, 3.10855873e-01,\n        3.10855873e-01, 3.17525009e-01, 3.17525009e-01, 3.24564654e-01,\n        3.24564654e-01, 3.39755465e-01, 3.39755465e-01, 3.42719526e-01,\n        3.43460541e-01, 3.57539830e-01, 3.58280845e-01, 3.58651352e-01,\n        3.58651352e-01, 3.64949981e-01, 3.64949981e-01, 3.65690997e-01,\n        3.65690997e-01, 3.69396073e-01, 3.69396073e-01, 3.73842164e-01,\n        3.74583179e-01, 3.76065209e-01, 3.76806225e-01, 3.87921452e-01,\n        3.88662468e-01, 4.00889218e-01, 4.00889218e-01, 4.12745461e-01,\n        4.12745461e-01, 4.29047795e-01, 4.29047795e-01, 4.29788811e-01,\n        4.29788811e-01, 4.30900333e-01, 4.31641349e-01, 4.32011856e-01,\n        4.32752871e-01, 4.40163023e-01, 4.40904039e-01, 4.56465358e-01,\n        4.56465358e-01, 4.69803631e-01, 4.69803631e-01, 4.80548351e-01,\n        4.80918859e-01, 4.86846980e-01, 4.86846980e-01, 4.89440534e-01,\n        4.89440534e-01, 4.95739163e-01, 4.95739163e-01, 5.12782512e-01,\n        5.12782512e-01, 5.19081141e-01, 5.19081141e-01, 5.24268247e-01,\n        5.24268247e-01, 5.25009263e-01, 5.25009263e-01, 5.29455354e-01,\n        5.29455354e-01, 5.30937384e-01, 5.31307892e-01, 5.35383475e-01,\n        5.35383475e-01, 5.36494998e-01, 5.36494998e-01, 5.47239718e-01,\n        5.47239718e-01, 5.49833272e-01, 5.50574287e-01, 5.50574287e-01,\n        5.62430530e-01, 5.62430530e-01, 5.72434235e-01, 5.72434235e-01,\n        5.80214894e-01, 5.80214894e-01, 5.83919970e-01, 5.83919970e-01,\n        5.85031493e-01, 5.85031493e-01, 5.93923675e-01, 5.94664691e-01,\n        5.95035198e-01, 5.98740274e-01, 5.98740274e-01, 6.04668396e-01,\n        6.04668396e-01, 6.06150426e-01, 6.06150426e-01, 6.06520934e-01,\n        6.06520934e-01, 6.07261949e-01, 6.07261949e-01, 6.08373472e-01,\n        6.08373472e-01, 6.15042608e-01, 6.15042608e-01, 6.15783624e-01,\n        6.15783624e-01, 6.16154131e-01, 6.16154131e-01, 6.17265654e-01,\n        6.17265654e-01, 6.20970730e-01, 6.20970730e-01, 6.27639867e-01,\n        6.27639867e-01, 6.44683216e-01, 6.44683216e-01, 6.47276769e-01,\n        6.47276769e-01, 6.58762505e-01, 6.58762505e-01, 6.60615043e-01,\n        6.60615043e-01, 6.62838088e-01, 6.62838088e-01, 6.63579103e-01,\n        6.63579103e-01, 6.74694331e-01, 6.75064839e-01, 6.90996665e-01,\n        6.91367173e-01, 6.93219711e-01, 6.93219711e-01, 6.94331234e-01,\n        6.94331234e-01, 6.95072249e-01, 6.95072249e-01, 7.07669507e-01,\n        7.07669507e-01, 7.08781030e-01, 7.08781030e-01, 7.12486106e-01,\n        7.12486106e-01, 7.12856614e-01, 7.12856614e-01, 7.15450167e-01,\n        7.15450167e-01, 7.15820674e-01, 7.15820674e-01, 7.28417933e-01,\n        7.28417933e-01, 7.29529455e-01, 7.29529455e-01, 7.31011486e-01,\n        7.31011486e-01, 7.36939607e-01, 7.36939607e-01, 7.39533160e-01,\n        7.39533160e-01, 7.41756206e-01, 7.41756206e-01, 7.42497221e-01,\n        7.42497221e-01, 7.43979252e-01, 7.43979252e-01, 7.45831790e-01,\n        7.45831790e-01, 7.50277881e-01, 7.50277881e-01, 7.58799555e-01,\n        7.58799555e-01, 7.61393109e-01, 7.61393109e-01, 7.62504631e-01,\n        7.62504631e-01, 7.64357169e-01, 7.64357169e-01, 7.67321230e-01,\n        7.67321230e-01, 7.69173768e-01, 7.69173768e-01, 7.69544276e-01,\n        7.69544276e-01, 7.73249352e-01, 7.73249352e-01, 7.73619859e-01,\n        7.73619859e-01, 7.75472397e-01, 7.75472397e-01, 7.75842905e-01,\n        7.75842905e-01, 7.78065950e-01, 7.78065950e-01, 7.79177473e-01,\n        7.79177473e-01, 7.84735087e-01, 7.84735087e-01, 7.85846610e-01,\n        7.85846610e-01, 7.86587625e-01, 7.86587625e-01, 7.88069655e-01,\n        7.88069655e-01, 7.92515747e-01, 7.92515747e-01, 7.96591330e-01,\n        7.96591330e-01, 7.97702853e-01, 7.97702853e-01, 7.99555391e-01,\n        7.99555391e-01, 8.01778436e-01, 8.01778436e-01, 8.02519452e-01,\n        8.02519452e-01, 8.06224528e-01, 8.06224528e-01, 8.08818081e-01,\n        8.08818081e-01, 8.09188588e-01, 8.09188588e-01, 8.13264172e-01,\n        8.13264172e-01, 8.15487217e-01, 8.15487217e-01, 8.15857725e-01,\n        8.15857725e-01, 8.16228233e-01, 8.16228233e-01, 8.16969248e-01,\n        8.16969248e-01, 8.18080771e-01, 8.18080771e-01, 8.20674324e-01,\n        8.20674324e-01, 8.21415339e-01, 8.21415339e-01, 8.22897369e-01,\n        8.22897369e-01, 8.24749907e-01, 8.24749907e-01, 8.28084476e-01,\n        8.28084476e-01, 8.28825491e-01, 8.28825491e-01, 8.30307521e-01,\n        8.30307521e-01, 8.32160059e-01, 8.32160059e-01, 8.32901074e-01,\n        8.32901074e-01, 8.33642090e-01, 8.33642090e-01, 8.36606150e-01,\n        8.36606150e-01, 8.37347166e-01, 8.37347166e-01, 8.38088181e-01,\n        8.38088181e-01, 8.38458688e-01, 8.38458688e-01, 8.45868840e-01,\n        8.45868840e-01, 8.46609856e-01, 8.46609856e-01, 8.46980363e-01,\n        8.46980363e-01, 8.49203409e-01, 8.49203409e-01, 8.49573916e-01,\n        8.49573916e-01, 8.49944424e-01, 8.49944424e-01, 8.50314931e-01,\n        8.50314931e-01, 8.50685439e-01, 8.50685439e-01, 8.54761023e-01,\n        8.54761023e-01, 8.55131530e-01, 8.55131530e-01, 8.55872545e-01,\n        8.55872545e-01, 8.56613561e-01, 8.56613561e-01, 8.56984068e-01,\n        8.56984068e-01, 8.57354576e-01, 8.57354576e-01, 8.57725083e-01,\n        8.57725083e-01, 8.59577621e-01, 8.59577621e-01, 8.61430159e-01,\n        8.61430159e-01, 8.63282697e-01, 8.63282697e-01, 8.64394220e-01,\n        8.64394220e-01, 8.64764728e-01, 8.64764728e-01, 8.65505743e-01,\n        8.65505743e-01, 8.65876250e-01, 8.65876250e-01, 8.66617266e-01,\n        8.66617266e-01, 8.67358281e-01, 8.67358281e-01, 8.69210819e-01,\n        8.69210819e-01, 8.70322342e-01, 8.70322342e-01, 8.71063357e-01,\n        8.71063357e-01, 8.72174880e-01, 8.72174880e-01, 8.72915895e-01,\n        8.72915895e-01, 8.74027418e-01, 8.74027418e-01, 8.75879956e-01,\n        8.75879956e-01, 8.75879956e-01, 8.76250463e-01, 8.76250463e-01,\n        8.76991478e-01, 8.76991478e-01, 8.79585031e-01, 8.79585031e-01,\n        8.80696554e-01, 8.80696554e-01, 8.81437569e-01, 8.81437569e-01,\n        8.81808077e-01, 8.81808077e-01, 8.82178585e-01, 8.82178585e-01,\n        8.82919600e-01, 8.82919600e-01, 8.83290107e-01, 8.83290107e-01,\n        8.83660615e-01, 8.83660615e-01, 8.84401630e-01, 8.84401630e-01,\n        8.85142645e-01, 8.85142645e-01, 8.85883661e-01, 8.85883661e-01,\n        8.88477214e-01, 8.88477214e-01, 8.90329752e-01, 8.90329752e-01,\n        8.90700259e-01, 8.90700259e-01, 8.91070767e-01, 8.91070767e-01,\n        8.91441275e-01, 8.91441275e-01, 8.92182290e-01, 8.92182290e-01,\n        8.92552797e-01, 8.92552797e-01, 8.93293813e-01, 8.93293813e-01,\n        8.94775843e-01, 8.94775843e-01, 8.95146351e-01, 8.95146351e-01,\n        8.96257873e-01, 8.96257873e-01, 8.96628381e-01, 8.96628381e-01,\n        8.96998888e-01, 8.96998888e-01, 8.97369396e-01, 8.97369396e-01,\n        8.98110411e-01, 8.98110411e-01, 8.98851426e-01, 8.98851426e-01,\n        9.00333457e-01, 9.00333457e-01, 9.00703964e-01, 9.00703964e-01,\n        9.01815487e-01, 9.01815487e-01, 9.02556502e-01, 9.02556502e-01,\n        9.03297518e-01, 9.03297518e-01, 9.04779548e-01, 9.04779548e-01,\n        9.05150056e-01, 9.05150056e-01, 9.05891071e-01, 9.05891071e-01,\n        9.06261578e-01, 9.06261578e-01, 9.06632086e-01, 9.06632086e-01,\n        9.07002594e-01, 9.07002594e-01, 9.07743609e-01, 9.07743609e-01,\n        9.08114116e-01, 9.08114116e-01, 9.08484624e-01, 9.08484624e-01,\n        9.08855132e-01, 9.08855132e-01, 9.09225639e-01, 9.09225639e-01,\n        9.09966654e-01, 9.09966654e-01, 9.10337162e-01, 9.10337162e-01,\n        9.11448685e-01, 9.11448685e-01, 9.12189700e-01, 9.12189700e-01,\n        9.12560207e-01, 9.12560207e-01, 9.12930715e-01, 9.12930715e-01,\n        9.13671730e-01, 9.13671730e-01, 9.14042238e-01, 9.14042238e-01,\n        9.14412745e-01, 9.14412745e-01, 9.15153761e-01, 9.15153761e-01,\n        9.15524268e-01, 9.15524268e-01, 9.16635791e-01, 9.16635791e-01,\n        9.17006299e-01, 9.17006299e-01, 9.17376806e-01, 9.17376806e-01,\n        9.17747314e-01, 9.17747314e-01, 9.18117821e-01, 9.18117821e-01,\n        9.18488329e-01, 9.18488329e-01, 9.18858837e-01, 9.18858837e-01,\n        9.19599852e-01, 9.19599852e-01, 9.19970359e-01, 9.19970359e-01,\n        9.20340867e-01, 9.20340867e-01, 9.20711375e-01, 9.20711375e-01,\n        9.21452390e-01, 9.21452390e-01, 9.21822897e-01, 9.21822897e-01,\n        9.22563913e-01, 9.22563913e-01, 9.23304928e-01, 9.23304928e-01,\n        9.23675435e-01, 9.23675435e-01, 9.24045943e-01, 9.24045943e-01,\n        9.24416451e-01, 9.24416451e-01, 9.24786958e-01, 9.24786958e-01,\n        9.25527973e-01, 9.25527973e-01, 9.25898481e-01, 9.25898481e-01,\n        9.26268989e-01, 9.26268989e-01, 9.26639496e-01, 9.26639496e-01,\n        9.27010004e-01, 9.27010004e-01, 9.28492034e-01, 9.28492034e-01,\n        9.28492034e-01, 9.28862542e-01, 9.28862542e-01, 9.29233049e-01,\n        9.29233049e-01, 9.29974064e-01, 9.29974064e-01, 9.31085587e-01,\n        9.31085587e-01, 9.31456095e-01, 9.31456095e-01, 9.32938125e-01,\n        9.32938125e-01, 9.33679140e-01, 9.33679140e-01, 9.34049648e-01,\n        9.34049648e-01, 9.34420156e-01, 9.34420156e-01, 9.35161171e-01,\n        9.35531678e-01, 9.35902186e-01, 9.35902186e-01, 9.36643201e-01,\n        9.36643201e-01, 9.37754724e-01, 9.37754724e-01, 9.38495739e-01,\n        9.38495739e-01, 9.38866247e-01, 9.38866247e-01, 9.39236754e-01,\n        9.39236754e-01, 9.39977770e-01, 9.39977770e-01, 9.40348277e-01,\n        9.40348277e-01, 9.41459800e-01, 9.41459800e-01, 9.42200815e-01,\n        9.42200815e-01, 9.42571323e-01, 9.42571323e-01, 9.42941830e-01,\n        9.42941830e-01, 9.43312338e-01, 9.43312338e-01, 9.43682845e-01,\n        9.43682845e-01, 9.44053353e-01, 9.44053353e-01, 9.44053353e-01,\n        9.44053353e-01, 9.44423861e-01, 9.44423861e-01, 9.44794368e-01,\n        9.44794368e-01, 9.44794368e-01, 9.45164876e-01, 9.45164876e-01,\n        9.45535383e-01, 9.45535383e-01, 9.45905891e-01, 9.45905891e-01,\n        9.46276399e-01, 9.46276399e-01, 9.46646906e-01, 9.46646906e-01,\n        9.47017414e-01, 9.47017414e-01, 9.47387921e-01, 9.47387921e-01,\n        9.47758429e-01, 9.47758429e-01, 9.48499444e-01, 9.48499444e-01,\n        9.48869952e-01, 9.48869952e-01, 9.49240459e-01, 9.49240459e-01,\n        9.49610967e-01, 9.49981475e-01, 9.49981475e-01, 9.50722490e-01,\n        9.50722490e-01, 9.51092997e-01, 9.51092997e-01, 9.51463505e-01,\n        9.51463505e-01, 9.51834013e-01, 9.51834013e-01, 9.52204520e-01,\n        9.52204520e-01, 9.52575028e-01, 9.52575028e-01, 9.52945535e-01,\n        9.52945535e-01, 9.53316043e-01, 9.53316043e-01, 9.53686551e-01,\n        9.53686551e-01, 9.54057058e-01, 9.54057058e-01, 9.54427566e-01,\n        9.54427566e-01, 9.54798073e-01, 9.54798073e-01, 9.54798073e-01,\n        9.54798073e-01, 9.55168581e-01, 9.55168581e-01, 9.55539089e-01,\n        9.55539089e-01, 9.55909596e-01, 9.55909596e-01, 9.56280104e-01,\n        9.56280104e-01, 9.56650611e-01, 9.56650611e-01, 9.57021119e-01,\n        9.57021119e-01, 9.57391627e-01, 9.57391627e-01, 9.57391627e-01,\n        9.57391627e-01, 9.57762134e-01, 9.57762134e-01, 9.58132642e-01,\n        9.58132642e-01, 9.58503149e-01, 9.58503149e-01, 9.58503149e-01,\n        9.58503149e-01, 9.58873657e-01, 9.58873657e-01, 9.59244165e-01,\n        9.59244165e-01, 9.59614672e-01, 9.59614672e-01, 9.59985180e-01,\n        9.59985180e-01, 9.60355687e-01, 9.60355687e-01, 9.61096702e-01,\n        9.61096702e-01, 9.61467210e-01, 9.61467210e-01, 9.61837718e-01,\n        9.61837718e-01, 9.62208225e-01, 9.62208225e-01, 9.62578733e-01,\n        9.62578733e-01, 9.62949240e-01, 9.62949240e-01, 9.63319748e-01,\n        9.63319748e-01, 9.63319748e-01, 9.63690256e-01, 9.63690256e-01,\n        9.64431271e-01, 9.64431271e-01, 9.64801778e-01, 9.64801778e-01,\n        9.65172286e-01, 9.65172286e-01, 9.65542794e-01, 9.65542794e-01,\n        9.65913301e-01, 9.65913301e-01, 9.66283809e-01, 9.66283809e-01,\n        9.66654316e-01, 9.66654316e-01, 9.67024824e-01, 9.67024824e-01,\n        9.67395332e-01, 9.67395332e-01, 9.67765839e-01, 9.67765839e-01,\n        9.68136347e-01, 9.68136347e-01, 9.68506854e-01, 9.68506854e-01,\n        9.68506854e-01, 9.68506854e-01, 9.68877362e-01, 9.68877362e-01,\n        9.69247870e-01, 9.69247870e-01, 9.69618377e-01, 9.69618377e-01,\n        9.69988885e-01, 9.69988885e-01, 9.70359392e-01, 9.70359392e-01,\n        9.71100408e-01, 9.71100408e-01, 9.71470915e-01, 9.71470915e-01,\n        9.71470915e-01, 9.71470915e-01, 9.71841423e-01, 9.71841423e-01,\n        9.72211930e-01, 9.72211930e-01, 9.72582438e-01, 9.72582438e-01,\n        9.72952946e-01, 9.72952946e-01, 9.73323453e-01, 9.73323453e-01,\n        9.73693961e-01, 9.73693961e-01, 9.73693961e-01, 9.73693961e-01,\n        9.74064468e-01, 9.74064468e-01, 9.74064468e-01, 9.74064468e-01,\n        9.74434976e-01, 9.74434976e-01, 9.74805484e-01, 9.74805484e-01,\n        9.74805484e-01, 9.74805484e-01, 9.74805484e-01, 9.74805484e-01,\n        9.75175991e-01, 9.75175991e-01, 9.75546499e-01, 9.75546499e-01,\n        9.75917006e-01, 9.75917006e-01, 9.76287514e-01, 9.76287514e-01,\n        9.76658021e-01, 9.76658021e-01, 9.76658021e-01, 9.76658021e-01,\n        9.77028529e-01, 9.77028529e-01, 9.77399037e-01, 9.77399037e-01,\n        9.77769544e-01, 9.77769544e-01, 9.78140052e-01, 9.78140052e-01,\n        9.78510559e-01, 9.78510559e-01, 9.78881067e-01, 9.78881067e-01,\n        9.79251575e-01, 9.79251575e-01, 9.79251575e-01, 9.79251575e-01,\n        9.79622082e-01, 9.79622082e-01, 9.79992590e-01, 9.79992590e-01,\n        9.79992590e-01, 9.79992590e-01, 9.80363097e-01, 9.80363097e-01,\n        9.80733605e-01, 9.80733605e-01, 9.81104113e-01, 9.81104113e-01,\n        9.81474620e-01, 9.81474620e-01, 9.81845128e-01, 9.81845128e-01,\n        9.81845128e-01, 9.81845128e-01, 9.82215635e-01, 9.82215635e-01,\n        9.82586143e-01, 9.82586143e-01, 9.82586143e-01, 9.82586143e-01,\n        9.82586143e-01, 9.82586143e-01, 9.82956651e-01, 9.82956651e-01,\n        9.83327158e-01, 9.83327158e-01, 9.83327158e-01, 9.83327158e-01,\n        9.83697666e-01, 9.83697666e-01, 9.84068173e-01, 9.84068173e-01,\n        9.84438681e-01, 9.84438681e-01, 9.84809189e-01, 9.84809189e-01,\n        9.85179696e-01, 9.85179696e-01, 9.85550204e-01, 9.85550204e-01,\n        9.85920711e-01, 9.85920711e-01, 9.85920711e-01, 9.85920711e-01,\n        9.86291219e-01, 9.86291219e-01, 9.86291219e-01, 9.86291219e-01,\n        9.86661727e-01, 9.86661727e-01, 9.86661727e-01, 9.86661727e-01,\n        9.87032234e-01, 9.87032234e-01, 9.87032234e-01, 9.87032234e-01,\n        9.87402742e-01, 9.87402742e-01, 9.87773249e-01, 9.87773249e-01,\n        9.88143757e-01, 9.88143757e-01, 9.88143757e-01, 9.88143757e-01,\n        9.88514265e-01, 9.88514265e-01, 9.88884772e-01, 9.88884772e-01,\n        9.89255280e-01, 9.89255280e-01, 9.89625787e-01, 9.89625787e-01,\n        9.89996295e-01, 9.89996295e-01, 9.90366803e-01, 9.90366803e-01,\n        9.90366803e-01, 9.90366803e-01, 9.90366803e-01, 9.90366803e-01,\n        9.90366803e-01, 9.90366803e-01, 9.90366803e-01, 9.90366803e-01,\n        9.90737310e-01, 9.90737310e-01, 9.91107818e-01, 9.91107818e-01,\n        9.91478325e-01, 9.91478325e-01, 9.91478325e-01, 9.91478325e-01,\n        9.91848833e-01, 9.91848833e-01, 9.92219340e-01, 9.92219340e-01,\n        9.92589848e-01, 9.92589848e-01, 9.93330863e-01, 9.93330863e-01,\n        9.93330863e-01, 9.93330863e-01, 9.93701371e-01, 9.93701371e-01,\n        9.94071878e-01, 9.94071878e-01, 9.94442386e-01, 9.94442386e-01,\n        9.94812894e-01, 9.94812894e-01, 9.94812894e-01, 9.94812894e-01,\n        9.94812894e-01, 9.94812894e-01, 9.95183401e-01, 9.95183401e-01,\n        9.95183401e-01, 9.95183401e-01, 9.95553909e-01, 9.95553909e-01,\n        9.95924416e-01, 9.95924416e-01, 9.96294924e-01, 9.96294924e-01,\n        9.96665432e-01, 9.96665432e-01, 9.97035939e-01, 9.97035939e-01,\n        9.97035939e-01, 9.97035939e-01, 9.97406447e-01, 9.97406447e-01,\n        9.97406447e-01, 9.97406447e-01, 9.97406447e-01, 9.97406447e-01,\n        9.97406447e-01, 9.97406447e-01, 9.97406447e-01, 9.97776954e-01,\n        9.97776954e-01, 9.97776954e-01, 9.97776954e-01, 9.98147462e-01,\n        9.98147462e-01, 9.98147462e-01, 9.98147462e-01, 9.98147462e-01,\n        9.98147462e-01, 9.98517970e-01, 9.98517970e-01, 9.98517970e-01,\n        9.98517970e-01, 9.98517970e-01, 9.98517970e-01, 9.98888477e-01,\n        9.98888477e-01, 9.99629492e-01, 9.99629492e-01, 1.00000000e+00,\n        1.00000000e+00, 1.00000000e+00, 1.00000000e+00]),\n array([1.99732733e+00, 9.97327328e-01, 9.96373475e-01, 9.96366382e-01,\n        9.96074438e-01, 9.96057153e-01, 9.95586276e-01, 9.95583236e-01,\n        9.95210946e-01, 9.95194972e-01, 9.94586945e-01, 9.94575024e-01,\n        9.94431198e-01, 9.94425416e-01, 9.93319631e-01, 9.93314564e-01,\n        9.93100047e-01, 9.93091345e-01, 9.92748678e-01, 9.92677689e-01,\n        9.92493987e-01, 9.92483795e-01, 9.92018640e-01, 9.92014408e-01,\n        9.91870284e-01, 9.91829574e-01, 9.91785288e-01, 9.91778135e-01,\n        9.91520107e-01, 9.91484225e-01, 9.91292536e-01, 9.91271555e-01,\n        9.90923226e-01, 9.90882277e-01, 9.90880489e-01, 9.90078449e-01,\n        9.90075767e-01, 9.89980519e-01, 9.89975870e-01, 9.88541603e-01,\n        9.88541126e-01, 9.87536967e-01, 9.87501860e-01, 9.86570299e-01,\n        9.86559868e-01, 9.86555099e-01, 9.86508608e-01, 9.86013889e-01,\n        9.86007512e-01, 9.85887229e-01, 9.85884845e-01, 9.85849023e-01,\n        9.85804319e-01, 9.85478759e-01, 9.85437751e-01, 9.85257566e-01,\n        9.85240638e-01, 9.85003531e-01, 9.84982431e-01, 9.84829485e-01,\n        9.84800220e-01, 9.84322250e-01, 9.84314442e-01, 9.83996928e-01,\n        9.83996093e-01, 9.82989490e-01, 9.82977033e-01, 9.82703984e-01,\n        9.82669115e-01, 9.81547475e-01, 9.81541276e-01, 9.81505334e-01,\n        9.81481194e-01, 9.81121421e-01, 9.81108725e-01, 9.81028855e-01,\n        9.81011629e-01, 9.80811477e-01, 9.80804026e-01, 9.80565012e-01,\n        9.80559707e-01, 9.80433106e-01, 9.80430543e-01, 9.79515493e-01,\n        9.79456127e-01, 9.78447020e-01, 9.78400588e-01, 9.77457106e-01,\n        9.77440119e-01, 9.75857317e-01, 9.75848794e-01, 9.75788295e-01,\n        9.75751758e-01, 9.75673318e-01, 9.75636005e-01, 9.75632787e-01,\n        9.75609422e-01, 9.74993587e-01, 9.74953234e-01, 9.73809004e-01,\n        9.73786771e-01, 9.72872317e-01, 9.72831666e-01, 9.72174942e-01,\n        9.72171664e-01, 9.71586406e-01, 9.71544981e-01, 9.71450388e-01,\n        9.71415937e-01, 9.70473289e-01, 9.70421612e-01, 9.68905807e-01,\n        9.68866646e-01, 9.68311012e-01, 9.68169093e-01, 9.67799604e-01,\n        9.67742860e-01, 9.67510045e-01, 9.67444062e-01, 9.66948867e-01,\n        9.66837943e-01, 9.66769755e-01, 9.66726959e-01, 9.66415882e-01,\n        9.66364145e-01, 9.66249049e-01, 9.66232002e-01, 9.65034723e-01,\n        9.65025783e-01, 9.64673102e-01, 9.64592099e-01, 9.64538515e-01,\n        9.62514758e-01, 9.62485313e-01, 9.60911453e-01, 9.60893810e-01,\n        9.59579468e-01, 9.59506571e-01, 9.58788574e-01, 9.58639085e-01,\n        9.58459258e-01, 9.58303690e-01, 9.56957400e-01, 9.56928313e-01,\n        9.56822276e-01, 9.56195474e-01, 9.56097782e-01, 9.55135107e-01,\n        9.55079556e-01, 9.54953432e-01, 9.54882026e-01, 9.54830170e-01,\n        9.54708993e-01, 9.54623401e-01, 9.54602242e-01, 9.54349279e-01,\n        9.54315960e-01, 9.53289270e-01, 9.53280151e-01, 9.53109801e-01,\n        9.52981710e-01, 9.52799320e-01, 9.52774942e-01, 9.52598035e-01,\n        9.52361405e-01, 9.51709569e-01, 9.51676130e-01, 9.49886918e-01,\n        9.49848950e-01, 9.45517421e-01, 9.45445716e-01, 9.45131898e-01,\n        9.45059180e-01, 9.42053616e-01, 9.41589415e-01, 9.41285670e-01,\n        9.40975785e-01, 9.40346360e-01, 9.40014839e-01, 9.39802468e-01,\n        9.39745486e-01, 9.36608553e-01, 9.36539948e-01, 9.31482255e-01,\n        9.31459308e-01, 9.31035638e-01, 9.31015015e-01, 9.30843711e-01,\n        9.30819333e-01, 9.30703342e-01, 9.30291831e-01, 9.23357844e-01,\n        9.23332930e-01, 9.23000216e-01, 9.22886193e-01, 9.20793056e-01,\n        9.20759618e-01, 9.20730829e-01, 9.20664132e-01, 9.19463575e-01,\n        9.19224679e-01, 9.19076324e-01, 9.18823421e-01, 9.13483620e-01,\n        9.13296163e-01, 9.12502408e-01, 9.12308991e-01, 9.11407948e-01,\n        9.11128998e-01, 9.07581627e-01, 9.07184124e-01, 9.06453967e-01,\n        9.06123996e-01, 9.04958248e-01, 9.04320776e-01, 9.03502524e-01,\n        9.03490186e-01, 9.02412772e-01, 9.02127147e-01, 9.01575208e-01,\n        9.01429653e-01, 8.98203611e-01, 8.98113668e-01, 8.92449915e-01,\n        8.91586185e-01, 8.90442371e-01, 8.90001178e-01, 8.89226377e-01,\n        8.89161348e-01, 8.87920797e-01, 8.87873948e-01, 8.84346664e-01,\n        8.83886337e-01, 8.81000161e-01, 8.80467951e-01, 8.80345106e-01,\n        8.79305065e-01, 8.74793530e-01, 8.73643994e-01, 8.73365581e-01,\n        8.72291565e-01, 8.70391250e-01, 8.69965196e-01, 8.69903028e-01,\n        8.69799018e-01, 8.67626369e-01, 8.66784334e-01, 8.64819586e-01,\n        8.64328563e-01, 8.55530560e-01, 8.55417490e-01, 8.54136527e-01,\n        8.54085565e-01, 8.53222430e-01, 8.52661312e-01, 8.52251828e-01,\n        8.52074921e-01, 8.46437514e-01, 8.46393704e-01, 8.36271882e-01,\n        8.35782290e-01, 8.32668602e-01, 8.32526684e-01, 8.25364351e-01,\n        8.24852169e-01, 8.21576416e-01, 8.19134235e-01, 8.17821145e-01,\n        8.14042985e-01, 8.09223473e-01, 8.07901919e-01, 8.02435577e-01,\n        7.98107982e-01, 7.97968030e-01, 7.97019482e-01, 7.89015293e-01,\n        7.87660956e-01, 7.78658092e-01, 7.78361917e-01, 7.76546657e-01,\n        7.76340842e-01, 7.75661528e-01, 7.74862587e-01, 7.73854136e-01,\n        7.73506820e-01, 7.71851242e-01, 7.71270573e-01, 7.67133176e-01,\n        7.66577005e-01, 7.66197741e-01, 7.64969289e-01, 7.60921180e-01,\n        7.60313272e-01, 7.54279256e-01, 7.52744913e-01, 7.42672741e-01,\n        7.40943134e-01, 7.34426439e-01, 7.34058917e-01, 7.26949632e-01,\n        7.26946950e-01, 7.16775179e-01, 7.15686679e-01, 7.14047670e-01,\n        7.13004768e-01, 7.11342275e-01, 7.11088598e-01, 6.97808802e-01,\n        6.96463227e-01, 6.93830490e-01, 6.92709208e-01, 6.89379573e-01,\n        6.84823096e-01, 6.84302270e-01, 6.82897270e-01, 6.58518672e-01,\n        6.49233043e-01, 6.45926058e-01, 6.41277432e-01, 6.40884638e-01,\n        6.36117280e-01, 6.10278666e-01, 6.09242260e-01, 6.07078969e-01,\n        6.04551613e-01, 6.03004396e-01, 6.00621641e-01, 6.00603819e-01,\n        5.99797845e-01, 5.97489059e-01, 5.95070362e-01, 5.78741670e-01,\n        5.75725496e-01, 5.74227154e-01, 5.73975503e-01, 5.70315838e-01,\n        5.67445934e-01, 5.65242410e-01, 5.64404488e-01, 5.62050283e-01,\n        5.58914363e-01, 5.52108884e-01, 5.45630217e-01, 5.43081880e-01,\n        5.39923012e-01, 5.31461954e-01, 5.29146492e-01, 5.15391767e-01,\n        5.03117502e-01, 4.95225251e-01, 4.94468510e-01, 4.80343223e-01,\n        4.73428637e-01, 4.67255771e-01, 4.65077400e-01, 4.55302984e-01,\n        4.50766683e-01, 4.50726599e-01, 4.49977070e-01, 4.45998222e-01,\n        4.32549596e-01, 4.29376602e-01, 4.29051250e-01, 4.18364346e-01,\n        4.17750001e-01, 4.14010823e-01, 4.13060129e-01, 4.12806600e-01,\n        4.10724223e-01, 4.04547334e-01, 3.92677814e-01, 3.88038218e-01,\n        3.84325802e-01, 3.81977588e-01, 3.74084234e-01, 3.57983798e-01,\n        3.54213238e-01, 3.53847712e-01, 3.53745580e-01, 3.51193100e-01,\n        3.45942765e-01, 3.35636824e-01, 3.18740070e-01, 3.18646938e-01,\n        3.13822448e-01, 3.13300371e-01, 3.09267253e-01, 3.07702601e-01,\n        3.03711861e-01, 3.00274491e-01, 2.98554063e-01, 2.92723000e-01,\n        2.85547674e-01, 2.77574897e-01, 2.75516391e-01, 2.73549378e-01,\n        2.72947103e-01, 2.68723279e-01, 2.66980648e-01, 2.66282856e-01,\n        2.53033757e-01, 2.51256555e-01, 2.49902636e-01, 2.48705834e-01,\n        2.38846511e-01, 2.38587469e-01, 2.25874305e-01, 2.25396544e-01,\n        2.23610684e-01, 2.18187451e-01, 2.18176171e-01, 2.17380777e-01,\n        2.15633601e-01, 2.15569079e-01, 2.11560339e-01, 2.11418942e-01,\n        2.11090475e-01, 2.10676178e-01, 2.05757827e-01, 2.05304071e-01,\n        1.97211996e-01, 1.97168306e-01, 1.96185172e-01, 1.93263814e-01,\n        1.88970447e-01, 1.86340779e-01, 1.85342029e-01, 1.79420277e-01,\n        1.78693593e-01, 1.78190142e-01, 1.77184299e-01, 1.73597321e-01,\n        1.70090124e-01, 1.68207988e-01, 1.66274205e-01, 1.61833659e-01,\n        1.60538629e-01, 1.58382475e-01, 1.57108694e-01, 1.56058878e-01,\n        1.54101551e-01, 1.52140141e-01, 1.48374408e-01, 1.46504611e-01,\n        1.44553885e-01, 1.36895970e-01, 1.33025885e-01, 1.31957725e-01,\n        1.31514668e-01, 1.29599512e-01, 1.28521919e-01, 1.26878485e-01,\n        1.26048565e-01, 1.21434748e-01, 1.21393047e-01, 1.20844804e-01,\n        1.20561756e-01, 1.19741835e-01, 1.17952332e-01, 1.17563561e-01,\n        1.15981452e-01, 1.10778749e-01, 1.10460982e-01, 1.09061405e-01,\n        1.06763177e-01, 1.05586596e-01, 1.04355499e-01, 1.03848837e-01,\n        1.02226704e-01, 1.01433292e-01, 1.00828253e-01, 1.00459866e-01,\n        9.92820039e-02, 9.66871753e-02, 9.58792791e-02, 9.31663960e-02,\n        9.27695408e-02, 9.22969431e-02, 9.20383632e-02, 9.20230597e-02,\n        9.11140293e-02, 9.08246711e-02, 9.07437876e-02, 8.79010558e-02,\n        8.72467011e-02, 8.66473094e-02, 8.64182189e-02, 8.61073583e-02,\n        8.57523382e-02, 8.28663185e-02, 8.13401043e-02, 8.12997818e-02,\n        8.12223181e-02, 7.87799284e-02, 7.83330202e-02, 7.64823481e-02,\n        7.64028057e-02, 7.58412406e-02, 7.55193308e-02, 7.55127296e-02,\n        7.53322020e-02, 7.50463903e-02, 7.50074685e-02, 7.34656230e-02,\n        7.28807598e-02, 7.27152750e-02, 7.25948364e-02, 7.24588335e-02,\n        7.20625371e-02, 7.12161511e-02, 7.11841658e-02, 7.11483136e-02,\n        7.00255707e-02, 6.87822551e-02, 6.85273930e-02, 6.59722909e-02,\n        6.53397739e-02, 6.51025772e-02, 6.47180229e-02, 6.42612725e-02,\n        6.38200939e-02, 6.29245415e-02, 6.29093796e-02, 6.26141503e-02,\n        6.25800565e-02, 6.07132614e-02, 6.06031455e-02, 5.96489497e-02,\n        5.92335723e-02, 5.92177175e-02, 5.91261089e-02, 5.84062003e-02,\n        5.83910495e-02, 5.72794639e-02, 5.61495684e-02, 5.55766486e-02,\n        5.54548427e-02, 5.41490093e-02, 5.27224503e-02, 5.20477407e-02,\n        5.20031154e-02, 5.16750142e-02, 5.15139773e-02, 5.14197908e-02,\n        5.08024134e-02, 4.98004407e-02, 4.97465730e-02, 4.89159450e-02,\n        4.81313057e-02, 4.79845069e-02, 4.79605868e-02, 4.69293222e-02,\n        4.68064770e-02, 4.64307033e-02, 4.57729399e-02, 4.57240008e-02,\n        4.56014238e-02, 4.54417877e-02, 4.47974913e-02, 4.47089076e-02,\n        4.46256436e-02, 4.46225330e-02, 4.29347679e-02, 4.29219082e-02,\n        4.27005552e-02, 4.21918742e-02, 4.12696935e-02, 4.12242636e-02,\n        4.03346047e-02, 4.01999876e-02, 4.01312560e-02, 4.00583334e-02,\n        3.99752893e-02, 3.97404060e-02, 3.92213576e-02, 3.90961617e-02,\n        3.90700363e-02, 3.83765884e-02, 3.83261032e-02, 3.78467701e-02,\n        3.70705910e-02, 3.66231389e-02, 3.65093276e-02, 3.64401191e-02,\n        3.62606794e-02, 3.61620113e-02, 3.56808640e-02, 3.56555693e-02,\n        3.55327949e-02, 3.53597142e-02, 3.44694480e-02, 3.44034880e-02,\n        3.36225815e-02, 3.35712619e-02, 3.35658491e-02, 3.35407741e-02,\n        3.35078873e-02, 3.33897397e-02, 3.33016850e-02, 3.13427970e-02,\n        3.11617628e-02, 3.04927975e-02, 3.03337760e-02, 3.01767569e-02,\n        3.00096087e-02, 2.87366472e-02, 2.87332162e-02, 2.84573231e-02,\n        2.81532370e-02, 2.81305183e-02, 2.80155893e-02, 2.75475327e-02,\n        2.74701584e-02, 2.64892466e-02, 2.59716101e-02, 2.57845521e-02,\n        2.57767495e-02, 2.56510116e-02, 2.56059784e-02, 2.54019313e-02,\n        2.53561046e-02, 2.53338832e-02, 2.52847075e-02, 2.52681207e-02,\n        2.51914207e-02, 2.51685325e-02, 2.45597418e-02, 2.45340634e-02,\n        2.44421232e-02, 2.44216826e-02, 2.38185264e-02, 2.38074176e-02,\n        2.33246908e-02, 2.32501533e-02, 2.31700260e-02, 2.31297407e-02,\n        2.30338089e-02, 2.28813533e-02, 2.28140559e-02, 2.28098817e-02,\n        2.27213055e-02, 2.27007307e-02, 2.23622117e-02, 2.23430581e-02,\n        2.17571370e-02, 2.17515733e-02, 2.17361078e-02, 2.16818880e-02,\n        2.14406215e-02, 2.14171037e-02, 2.08656006e-02, 2.08108481e-02,\n        2.03980710e-02, 2.03450676e-02, 1.96695905e-02, 1.96627975e-02,\n        1.88467391e-02, 1.88456643e-02, 1.86028238e-02, 1.85088553e-02,\n        1.82304941e-02, 1.80746932e-02, 1.80579908e-02, 1.79868247e-02,\n        1.79282315e-02, 1.79262254e-02, 1.72768608e-02, 1.72391422e-02,\n        1.70360841e-02, 1.69130322e-02, 1.65313855e-02, 1.65297259e-02,\n        1.65293310e-02, 1.65237430e-02, 1.62706822e-02, 1.62483659e-02,\n        1.60886999e-02, 1.60299223e-02, 1.60028823e-02, 1.59994215e-02,\n        1.57767851e-02, 1.57571528e-02, 1.56775210e-02, 1.56001439e-02,\n        1.55611243e-02, 1.55556342e-02, 1.54682342e-02, 1.53974276e-02,\n        1.51843773e-02, 1.51663767e-02, 1.49242627e-02, 1.49096129e-02,\n        1.40827484e-02, 1.40762348e-02, 1.38843292e-02, 1.38690071e-02,\n        1.38580371e-02, 1.36085795e-02, 1.35975806e-02, 1.26821464e-02,\n        1.26240645e-02, 1.25006437e-02, 1.24967657e-02, 1.20746261e-02,\n        1.20601635e-02, 1.16093829e-02, 1.15937879e-02, 1.14492178e-02,\n        1.14064813e-02, 1.11783361e-02, 1.11537026e-02, 1.09892851e-02,\n        1.09669706e-02, 1.05127990e-02, 1.05052078e-02, 1.04560824e-02,\n        1.04232067e-02, 1.04038892e-02, 1.03824222e-02, 9.98690818e-03,\n        9.97606479e-03, 9.79342870e-03, 9.78456438e-03, 9.34689771e-03,\n        9.33227129e-03, 9.28113144e-03, 9.25299898e-03, 8.95948801e-03,\n        8.95594526e-03, 8.49708635e-03, 8.45904741e-03, 8.45204294e-03,\n        8.45172629e-03, 8.37135967e-03, 8.36794823e-03, 8.07013363e-03,\n        8.05410277e-03, 7.95074925e-03, 7.94992968e-03, 7.82861933e-03,\n        7.82482699e-03, 7.64047448e-03, 7.63769075e-03, 7.62895355e-03,\n        7.62765063e-03, 7.60675827e-03, 7.59948371e-03, 7.41170906e-03,\n        7.40554417e-03, 7.40454253e-03, 7.40277255e-03, 7.31270248e-03,\n        7.26989796e-03, 6.97114272e-03, 6.97097788e-03, 6.81238854e-03,\n        6.80389581e-03, 6.78060018e-03, 6.77463273e-03, 6.40218658e-03,\n        6.39733206e-03, 6.36489410e-03, 6.34531351e-03, 6.33007381e-03,\n        6.32913783e-03, 6.16380805e-03, 6.16273051e-03, 5.97291905e-03,\n        5.97227924e-03, 5.81617793e-03, 5.81188686e-03, 5.75407548e-03,\n        5.75327873e-03, 5.72279096e-03, 5.72275091e-03, 5.54109737e-03,\n        5.53386519e-03, 5.42298146e-03, 5.42173116e-03, 5.36474353e-03,\n        5.36032859e-03, 5.31825330e-03, 5.30706299e-03, 5.25499368e-03,\n        5.25045209e-03, 5.12529397e-03, 5.11959381e-03, 5.08467620e-03,\n        5.08390414e-03, 5.05014835e-03, 5.04734134e-03, 4.78606485e-03,\n        4.78242943e-03, 4.68959240e-03, 4.68655117e-03, 4.67558950e-03,\n        4.67507914e-03, 4.59464174e-03, 4.59423009e-03, 4.58078226e-03,\n        4.57961019e-03, 4.14878409e-03, 4.14397568e-03, 4.10413276e-03,\n        4.10148129e-03, 3.98651836e-03, 3.98092903e-03, 3.90141015e-03,\n        3.89430113e-03, 3.88418674e-03, 3.88323120e-03, 3.88296926e-03,\n        3.88065190e-03, 3.78797576e-03, 3.78489634e-03, 3.65631143e-03,\n        3.65616544e-03, 3.54990689e-03, 3.54927452e-03, 3.52686062e-03,\n        3.52302473e-03, 3.50166112e-03, 3.49953701e-03, 3.43868393e-03,\n        3.43708275e-03, 3.37060983e-03, 3.36923730e-03, 3.29342228e-03,\n        3.29256477e-03, 3.15028313e-03, 3.14979488e-03, 3.14485189e-03,\n        3.14257457e-03, 2.98069697e-03, 2.97851535e-03, 2.81141768e-03,\n        2.81034154e-03, 2.79607391e-03, 2.79511395e-03, 2.74956413e-03,\n        2.74695433e-03, 2.65279086e-03, 2.65016034e-03, 2.62210029e-03,\n        2.62018456e-03, 2.60915980e-03, 2.60796119e-03, 2.59206886e-03,\n        2.58976454e-03, 2.58854288e-03, 2.58445903e-03, 2.46665324e-03,\n        2.46623089e-03, 2.36062403e-03, 2.35819514e-03, 2.29890039e-03,\n        2.29790946e-03, 2.29766802e-03, 2.29697628e-03, 2.16000178e-03,\n        2.15910934e-03, 2.15316401e-03, 2.15163524e-03, 2.09957897e-03,\n        2.09940225e-03, 1.99143379e-03, 1.99004216e-03, 1.91815617e-03,\n        1.91787886e-03, 1.84667076e-03, 1.84629124e-03, 1.80760131e-03,\n        1.80757476e-03, 1.80694251e-03, 1.80592085e-03, 1.74103759e-03,\n        1.73963991e-03, 1.64701452e-03, 1.64595025e-03, 1.64493965e-03,\n        1.64242787e-03, 1.61917694e-03, 1.61775539e-03, 1.61461183e-03,\n        1.61451881e-03, 1.56083866e-03, 1.56025472e-03, 1.55062170e-03,\n        1.55027339e-03, 1.46029051e-03, 1.45983312e-03, 1.36525487e-03,\n        1.36485184e-03, 1.34883227e-03, 1.34746672e-03, 1.31846499e-03,\n        1.31744705e-03, 1.27826969e-03, 1.27539737e-03, 1.25537976e-03,\n        1.25466974e-03, 1.20770966e-03, 1.20724272e-03, 1.16567372e-03,\n        1.16438698e-03, 1.14409789e-03, 1.14335760e-03, 1.12619996e-03,\n        1.12560892e-03, 1.10274705e-03, 1.10221049e-03, 1.06629869e-03,\n        1.06582243e-03, 1.00514048e-03, 1.00501941e-03, 9.48158675e-04,\n        9.47762164e-04, 9.13176511e-04, 9.13076510e-04, 9.05686000e-04,\n        9.05241584e-04, 8.93668272e-04, 8.93638469e-04, 8.87215952e-04,\n        8.86706752e-04, 8.21226102e-04, 8.20432266e-04, 7.81510200e-04,\n        7.78293994e-04, 7.74379761e-04, 7.74337619e-04, 7.71189982e-04,\n        7.69992708e-04, 7.58164504e-04, 7.58161943e-04, 7.06799910e-04,\n        7.05135055e-04, 6.92371104e-04, 6.90305198e-04, 6.90271729e-04,\n        6.37133897e-04, 6.37037039e-04, 6.14911900e-04, 6.13999204e-04,\n        6.02651620e-04, 6.02303538e-04, 5.94283920e-04, 5.93920180e-04,\n        5.71538461e-04, 5.69141703e-04, 5.17919252e-04, 5.17486013e-04,\n        3.77362972e-04, 3.77163378e-04, 3.71255534e-04, 3.69735673e-04,\n        3.65445565e-04, 3.64351319e-04, 3.54685646e-04, 3.54153657e-04,\n        2.85770395e-04, 2.82362860e-04, 2.60819274e-04], dtype=float32))"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_true, y_pred_flatten)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91      5365\n",
      "         1.0       0.97      0.63      0.76      2699\n",
      "\n",
      "    accuracy                           0.87      8064\n",
      "   macro avg       0.90      0.81      0.83      8064\n",
      "weighted avg       0.88      0.87      0.86      8064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_flatten.round(decimals=1).astype(int)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94      5365\n",
      "         1.0       0.95      0.79      0.86      2699\n",
      "\n",
      "    accuracy                           0.92      8064\n",
      "   macro avg       0.93      0.88      0.90      8064\n",
      "weighted avg       0.92      0.92      0.91      8064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, list(map(lambda f: (f > 0.85) and 1 or 0, y_pred_flatten))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nyaural_nyatworks'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdjango\u001B[39;00m\n\u001B[0;32m      4\u001B[0m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDJANGO_SETTINGS_MODULE\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnya_app.nyaural_nyatworks.settings\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mdjango\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\django\\__init__.py:19\u001B[0m, in \u001B[0;36msetup\u001B[1;34m(set_prefix)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdjango\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01murls\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_script_prefix\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdjango\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m configure_logging\n\u001B[1;32m---> 19\u001B[0m configure_logging(\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLOGGING_CONFIG\u001B[49m, settings\u001B[38;5;241m.\u001B[39mLOGGING)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m set_prefix:\n\u001B[0;32m     21\u001B[0m     set_script_prefix(\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mFORCE_SCRIPT_NAME \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mFORCE_SCRIPT_NAME\n\u001B[0;32m     23\u001B[0m     )\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\django\\conf\\__init__.py:87\u001B[0m, in \u001B[0;36mLazySettings.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m\"\"\"Return the value of a setting and cache it in self.__dict__.\"\"\"\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrapped \u001B[38;5;129;01mis\u001B[39;00m empty:\n\u001B[1;32m---> 87\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrapped, name)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Special case some settings which require further modification.\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;66;03m# This is done here for performance reasons so the modified value is cached.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\django\\conf\\__init__.py:74\u001B[0m, in \u001B[0;36mLazySettings._setup\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m     66\u001B[0m     desc \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msetting \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m name) \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msettings\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ImproperlyConfigured(\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequested \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, but settings are not configured. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     69\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must either define the environment variable \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     70\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor call settings.configure() before accessing settings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m         \u001B[38;5;241m%\u001B[39m (desc, ENVIRONMENT_VARIABLE)\n\u001B[0;32m     72\u001B[0m     )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrapped \u001B[38;5;241m=\u001B[39m \u001B[43mSettings\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\uiqko\\pyenvs\\mint\\lib\\site-packages\\django\\conf\\__init__.py:183\u001B[0m, in \u001B[0;36mSettings.__init__\u001B[1;34m(self, settings_module)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;66;03m# store the settings module in case someone later cares\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mSETTINGS_MODULE \u001B[38;5;241m=\u001B[39m settings_module\n\u001B[1;32m--> 183\u001B[0m mod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSETTINGS_MODULE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m tuple_settings \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mALLOWED_HOSTS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINSTALLED_APPS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTEMPLATE_DIRS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLOCALE_PATHS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    190\u001B[0m )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_explicit_settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:972\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:228\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:984\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'nyaural_nyatworks'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'nya_app.nyaural_nyatworks.settings')\n",
    "django.setup()\n",
    "\n",
    "from nya_app.nyaural_nyatworks.models import Report, Tag\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md = \"\"\"\n",
    "# RuBert для классификации токсичных текстов от Сколковского института\n",
    "## Тестирование на датасетах\n",
    "### Russian toxic comments form 2ch, Pikabu (Kaggle)\n",
    "### Roc curve\n",
    "![](roc_curve_kaggle_2ch_pikabu_toxic_skolkovo.png)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_rep = Report(\n",
    "    title='RuBert SkolkovoInstitute',\n",
    "    text=md,\n",
    "    tags=[\n",
    "        Tag('toxic', grad=1),\n",
    "        Tag('best', grad=0),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}