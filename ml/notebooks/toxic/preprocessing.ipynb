{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from preprocessing.transformers import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('../data/train.csv', header=0, index_col='id')\n",
    "test = pd.read_csv('../data/test.csv', header=0, index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train = train['comment_text']\n",
    "Y_train = train.drop('comment_text', axis=1)\n",
    "\n",
    "X_test = test.comment_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('cleaner', Cleaner()),\n",
    "    ('splitter', Splitter()),\n",
    "    ('stopwords_remover', StopWordsRemover()),\n",
    "    ('stemmer', Stemmer().with_stemmer('snowball', language='english')),\n",
    "    ('lemmatizer', Lemmatizer()),\n",
    "    ('tokenizer', Tokenizer(pad=True))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2]], dtype=int32)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline.fit_transform(['Hello is not to be the baby'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = '''\n",
    "But do cats eat bats, I wonder?' And here Alice began to get\n",
    "rather sleepy, and went on saying to herself, in a dreamy sort of\n",
    "way, `Do cats eat bats?  Do cats eat bats?' and sometimes, `Do\n",
    "bats eat cats?' for, you see, as she couldn't answer either\n",
    "question, it didn't much matter which way she put it.  She felt\n",
    "that she was dozing off, and had just begun to dream that she\n",
    "was walking hand in hand with Dinah, and saying to her very\n",
    "earnestly, `Now, Dinah, tell me the truth:  did you ever eat a\n",
    "bat?' when suddenly, thump! thump! down she came upon a heap of\n",
    "sticks and dry leaves, and the fall was over.\n",
    "'''\n",
    "\n",
    "' '.join(map(str, preprocessing_pipeline.fit_transform([text])[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'12 3 1 2 13 14 15 16 17 18 19 20 21 5 22 23 6 4 3 1 2 4 3 1 2 24 4 2 1 3 25 26 27 28 29 30 31 32 6 33 34 35 36 37 38 39 7 7 8 5 40 41 8 42 43 44 1 2 45 9 9 46 47 48 49 50 51 52'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('cleaner', Cleaner()),\n",
    "        ('splitter', Splitter()),\n",
    "        ('stopwords_remover', StopWordsRemover()),\n",
    "        ('stemmer', Stemmer().with_stemmer('snowball', language='english')),\n",
    "        ('lemmatizer', Lemmatizer()),\n",
    "        ('tokenizer', Tokenizer(pad=True))\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('cleaner', Cleaner()),\n  ('splitter', Splitter()),\n  ('stopwords_remover', StopWordsRemover()),\n  ('stemmer', Stemmer()),\n  ('lemmatizer', Lemmatizer()),\n  ('tokenizer',\n   Tokenizer(pad=True,\n             tokenizer=<keras_preprocessing.text.Tokenizer object at 0x7f0c9124e130>))],\n 'verbose': True,\n 'cleaner': Cleaner(),\n 'splitter': Splitter(),\n 'stopwords_remover': StopWordsRemover(),\n 'stemmer': Stemmer(),\n 'lemmatizer': Lemmatizer(),\n 'tokenizer': Tokenizer(pad=True,\n           tokenizer=<keras_preprocessing.text.Tokenizer object at 0x7f0c9124e130>),\n 'cleaner__addresses': True,\n 'cleaner__dates': True,\n 'cleaner__emails': True,\n 'cleaner__ips': True,\n 'cleaner__links': True,\n 'cleaner__punctuation': True,\n 'stopwords_remover__language': 'english',\n 'tokenizer__pad': True,\n 'tokenizer__pad_len': None,\n 'tokenizer__tokenizer': <keras_preprocessing.text.Tokenizer at 0x7f0c9124e130>}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 6) Processing cleaner, total=  51.4s\n",
      "[Pipeline] .......... (step 2 of 6) Processing splitter, total=   2.4s\n",
      "[Pipeline] . (step 3 of 6) Processing stopwords_remover, total=   9.6s\n",
      "[Pipeline] ........... (step 4 of 6) Processing stemmer, total=  38.0s\n",
      "[Pipeline] ........ (step 5 of 6) Processing lemmatizer, total=  13.2s\n",
      "[Pipeline] ......... (step 6 of 6) Processing tokenizer, total=   3.6s\n",
      "[Pipeline] ........... (step 1 of 6) Processing cleaner, total=  45.6s\n",
      "[Pipeline] .......... (step 2 of 6) Processing splitter, total=   2.1s\n",
      "[Pipeline] . (step 3 of 6) Processing stopwords_remover, total=   8.5s\n",
      "[Pipeline] ........... (step 4 of 6) Processing stemmer, total=  34.4s\n",
      "[Pipeline] ........ (step 5 of 6) Processing lemmatizer, total=  11.9s\n",
      "[Pipeline] ......... (step 6 of 6) Processing tokenizer, total=   4.1s\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline.fit(X_train)\n",
    "preprocessing_pipeline.fit(X_test)\n",
    "\n",
    "X_train = preprocessing_pipeline.transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_test = preprocessing_pipeline.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    fname='../data/prepared_train.csv',\n",
    "    X=X_train,\n",
    "    delimiter=',',\n",
    "    fmt='%i'\n",
    ")\n",
    "np.savetxt(\n",
    "    fname='../data/prepared_test.csv',\n",
    "    X=X_test,\n",
    "    delimiter=',',\n",
    "    fmt='%i'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('../data/tokenizer.json', 'w') as file:\n",
    "    file.write(\n",
    "        preprocessing_pipeline['tokenizer'].tokenizer.to_json()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 954, in _bootstrap_inner\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 954, in _bootstrap_inner\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 954, in _bootstrap_inner\n",
      "        self.run()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 892, in run\n",
      "self.run()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 892, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1162, in _worker_loop\n",
      "        tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "self._target(*self._args, **self._kwargs)  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 951, in _do_train_job\n",
      "\n",
      "  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1162, in _worker_loop\n",
      "    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 542, in gensim.models.word2vec_inner.train_batch_sg\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 951, in _do_train_job\n",
      "        self.run()\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 892, in run\n",
      "tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 542, in gensim.models.word2vec_inner.train_batch_sg\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1162, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/home/uiqkos/pyenvs/mint/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 951, in _do_train_job\n",
      "    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 542, in gensim.models.word2vec_inner.train_batch_sg\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "# todo add CBOW, Glove, FastText\n",
    "\n",
    "word2vec_models = dict(\n",
    "    light=Word2Vec( # Skip-gram\n",
    "        sentences=np.concatenate([X_train, X_test], axis=0),\n",
    "        sg=True,\n",
    "        window=5,\n",
    "        vector_size=100,\n",
    "        min_count=1,\n",
    "        negative=15\n",
    "    ),\n",
    "    heavy=Word2Vec( # Skip-gram\n",
    "        sentences=np.concatenate([X_train, X_test], axis=0),\n",
    "        sg=True,\n",
    "        window=10,\n",
    "        vector_size=300,\n",
    "        min_count=1,\n",
    "        negative=20\n",
    "    ),\n",
    ")\n",
    "\n",
    "for name, model in word2vec_models:\n",
    "    model.save(name + '_word2vec.model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}